{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[0,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "testLayer = ReLULayer()\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3012422546308207"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import TwoLayerNet\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "\n",
    "#Now implement regularizaion\n",
    "model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for hidden_W parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for hidden_B parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for output_W parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for output_B parameter\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for hidden_W parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for hidden_B parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for output_W parameter\n",
      "Gradient check passed!\n",
      "Checking gradient for output_B parameter\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.301046, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.294846, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.262451, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.291643, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.271335, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.249244, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.311938, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.224650, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.310488, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.287230, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.243316, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.323646, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.292502, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.193651, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.273020, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.204563, Train accuracy: 0.240111, val accuracy: 0.228000\n",
      "Loss: 2.144456, Train accuracy: 0.249889, val accuracy: 0.249000\n",
      "Loss: 2.204682, Train accuracy: 0.265000, val accuracy: 0.263000\n",
      "Loss: 2.171291, Train accuracy: 0.273444, val accuracy: 0.271000\n",
      "Loss: 2.237730, Train accuracy: 0.284000, val accuracy: 0.281000\n",
      "Loss: 1.968246, Train accuracy: 0.293889, val accuracy: 0.283000\n",
      "Loss: 2.042029, Train accuracy: 0.300333, val accuracy: 0.286000\n",
      "Loss: 2.300786, Train accuracy: 0.306222, val accuracy: 0.295000\n",
      "Loss: 1.958206, Train accuracy: 0.307556, val accuracy: 0.299000\n",
      "Loss: 1.934839, Train accuracy: 0.307778, val accuracy: 0.294000\n",
      "Loss: 2.088664, Train accuracy: 0.309556, val accuracy: 0.297000\n",
      "Loss: 2.423954, Train accuracy: 0.310556, val accuracy: 0.296000\n",
      "Loss: 2.080679, Train accuracy: 0.311444, val accuracy: 0.294000\n",
      "Loss: 2.061023, Train accuracy: 0.310444, val accuracy: 0.295000\n",
      "Loss: 2.024816, Train accuracy: 0.312667, val accuracy: 0.300000\n",
      "Loss: 1.697073, Train accuracy: 0.311889, val accuracy: 0.295000\n",
      "Loss: 1.604473, Train accuracy: 0.315111, val accuracy: 0.295000\n",
      "Loss: 1.858294, Train accuracy: 0.314889, val accuracy: 0.300000\n",
      "Loss: 1.609010, Train accuracy: 0.316111, val accuracy: 0.298000\n",
      "Loss: 1.920981, Train accuracy: 0.318111, val accuracy: 0.303000\n",
      "Loss: 2.431444, Train accuracy: 0.319889, val accuracy: 0.302000\n",
      "Loss: 1.984418, Train accuracy: 0.318222, val accuracy: 0.299000\n",
      "Loss: 1.971440, Train accuracy: 0.321222, val accuracy: 0.302000\n",
      "Loss: 1.554755, Train accuracy: 0.320556, val accuracy: 0.302000\n",
      "Loss: 1.603166, Train accuracy: 0.321667, val accuracy: 0.310000\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer, Dataset\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(),num_epochs=20, learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0bf99759e8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0bf998f080>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.328676, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.332502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269842, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269898, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.318512, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286142, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286562, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251858, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321440, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286162, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.330472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281353, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279406, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287826, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266662, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.317896, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309036, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.329036, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293804, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287194, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276315, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308587, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234576, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.334706, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.338872, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298660, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347115, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.335010, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227760, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306940, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.263506, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301325, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-df0483226c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# You should expect this to reach 1.0 training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=15, learning_rate_decay=0.99)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.305836, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.300645, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.296028, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.291615, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.287185, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.282270, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.275822, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.265455, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.245912, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.206874, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.135862, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.051694, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.006157, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.974474, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.947721, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.921633, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.894719, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.867644, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.841182, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.816770, Train accuracy: 0.333333, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=4e-1, num_epochs=20, batch_size=15)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.000000, Loss: 2.248490, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1.000000, Loss: 2.319471, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2.000000, Loss: 2.146110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3.000000, Loss: 2.071886, Train accuracy: 0.210667, val accuracy: 0.225000\n",
      "Epoch: 4.000000, Loss: 2.230434, Train accuracy: 0.228778, val accuracy: 0.249000\n",
      "Epoch: 5.000000, Loss: 2.028859, Train accuracy: 0.244333, val accuracy: 0.268000\n",
      "Epoch: 6.000000, Loss: 1.961512, Train accuracy: 0.261222, val accuracy: 0.288000\n",
      "Epoch: 7.000000, Loss: 2.019076, Train accuracy: 0.286889, val accuracy: 0.315000\n",
      "Epoch: 8.000000, Loss: 1.971225, Train accuracy: 0.317444, val accuracy: 0.350000\n",
      "Epoch: 9.000000, Loss: 2.247622, Train accuracy: 0.331333, val accuracy: 0.354000\n",
      "Epoch: 10.000000, Loss: 2.020500, Train accuracy: 0.346000, val accuracy: 0.360000\n",
      "Epoch: 11.000000, Loss: 1.713808, Train accuracy: 0.363000, val accuracy: 0.380000\n",
      "Epoch: 12.000000, Loss: 2.038986, Train accuracy: 0.376222, val accuracy: 0.394000\n",
      "Epoch: 13.000000, Loss: 1.726021, Train accuracy: 0.403222, val accuracy: 0.415000\n",
      "Epoch: 14.000000, Loss: 1.448154, Train accuracy: 0.423889, val accuracy: 0.441000\n",
      "Epoch: 15.000000, Loss: 1.907794, Train accuracy: 0.451111, val accuracy: 0.469000\n",
      "Epoch: 16.000000, Loss: 1.702461, Train accuracy: 0.470889, val accuracy: 0.481000\n",
      "Epoch: 17.000000, Loss: 1.582746, Train accuracy: 0.489222, val accuracy: 0.491000\n",
      "Epoch: 18.000000, Loss: 1.735784, Train accuracy: 0.496111, val accuracy: 0.497000\n",
      "Epoch: 19.000000, Loss: 1.922509, Train accuracy: 0.498333, val accuracy: 0.512000\n",
      "Epoch: 20.000000, Loss: 1.526623, Train accuracy: 0.509556, val accuracy: 0.515000\n",
      "Epoch: 21.000000, Loss: 1.543858, Train accuracy: 0.511778, val accuracy: 0.520000\n",
      "Epoch: 22.000000, Loss: 1.636253, Train accuracy: 0.518333, val accuracy: 0.532000\n",
      "Epoch: 23.000000, Loss: 1.528210, Train accuracy: 0.523667, val accuracy: 0.534000\n",
      "Epoch: 24.000000, Loss: 1.685593, Train accuracy: 0.510000, val accuracy: 0.530000\n",
      "Epoch: 25.000000, Loss: 1.676758, Train accuracy: 0.526667, val accuracy: 0.542000\n",
      "Epoch: 26.000000, Loss: 1.483751, Train accuracy: 0.531333, val accuracy: 0.545000\n",
      "Epoch: 27.000000, Loss: 1.628531, Train accuracy: 0.536889, val accuracy: 0.548000\n",
      "Epoch: 28.000000, Loss: 1.470980, Train accuracy: 0.541111, val accuracy: 0.545000\n",
      "Epoch: 29.000000, Loss: 1.194893, Train accuracy: 0.547000, val accuracy: 0.549000\n",
      "Epoch: 30.000000, Loss: 1.712995, Train accuracy: 0.544333, val accuracy: 0.545000\n",
      "Epoch: 31.000000, Loss: 1.553598, Train accuracy: 0.543111, val accuracy: 0.550000\n",
      "Epoch: 32.000000, Loss: 1.715235, Train accuracy: 0.545889, val accuracy: 0.543000\n",
      "Epoch: 33.000000, Loss: 1.793639, Train accuracy: 0.549889, val accuracy: 0.543000\n",
      "Epoch: 34.000000, Loss: 1.278433, Train accuracy: 0.554556, val accuracy: 0.553000\n",
      "Epoch: 35.000000, Loss: 1.338119, Train accuracy: 0.560222, val accuracy: 0.553000\n",
      "Epoch: 36.000000, Loss: 1.406414, Train accuracy: 0.554333, val accuracy: 0.551000\n",
      "Epoch: 37.000000, Loss: 1.074617, Train accuracy: 0.565333, val accuracy: 0.553000\n",
      "Epoch: 38.000000, Loss: 1.564786, Train accuracy: 0.564000, val accuracy: 0.556000\n",
      "Epoch: 39.000000, Loss: 1.375361, Train accuracy: 0.563000, val accuracy: 0.557000\n",
      "Epoch: 40.000000, Loss: 1.280123, Train accuracy: 0.566333, val accuracy: 0.554000\n",
      "Epoch: 41.000000, Loss: 1.474169, Train accuracy: 0.564333, val accuracy: 0.555000\n",
      "Epoch: 42.000000, Loss: 1.518031, Train accuracy: 0.564000, val accuracy: 0.545000\n",
      "Epoch: 43.000000, Loss: 0.978323, Train accuracy: 0.565778, val accuracy: 0.554000\n",
      "Epoch: 44.000000, Loss: 1.477377, Train accuracy: 0.571222, val accuracy: 0.555000\n",
      "Epoch: 45.000000, Loss: 1.336894, Train accuracy: 0.574222, val accuracy: 0.565000\n",
      "Epoch: 46.000000, Loss: 1.514178, Train accuracy: 0.570111, val accuracy: 0.556000\n",
      "Epoch: 47.000000, Loss: 1.387563, Train accuracy: 0.572778, val accuracy: 0.554000\n",
      "Epoch: 48.000000, Loss: 1.447459, Train accuracy: 0.577333, val accuracy: 0.566000\n",
      "Epoch: 49.000000, Loss: 1.442454, Train accuracy: 0.576333, val accuracy: 0.558000\n",
      "Epoch: 50.000000, Loss: 1.708501, Train accuracy: 0.579889, val accuracy: 0.563000\n",
      "Epoch: 51.000000, Loss: 1.533563, Train accuracy: 0.574556, val accuracy: 0.560000\n",
      "Epoch: 52.000000, Loss: 1.279643, Train accuracy: 0.584000, val accuracy: 0.568000\n",
      "Epoch: 53.000000, Loss: 1.318732, Train accuracy: 0.583444, val accuracy: 0.571000\n",
      "Epoch: 54.000000, Loss: 1.528352, Train accuracy: 0.591111, val accuracy: 0.573000\n",
      "Epoch: 55.000000, Loss: 1.462334, Train accuracy: 0.586333, val accuracy: 0.556000\n",
      "Epoch: 56.000000, Loss: 1.499915, Train accuracy: 0.586333, val accuracy: 0.568000\n",
      "Epoch: 57.000000, Loss: 1.079293, Train accuracy: 0.590667, val accuracy: 0.571000\n",
      "Epoch: 58.000000, Loss: 1.609913, Train accuracy: 0.592000, val accuracy: 0.571000\n",
      "Epoch: 59.000000, Loss: 1.452583, Train accuracy: 0.584444, val accuracy: 0.559000\n",
      "Epoch: 60.000000, Loss: 1.500014, Train accuracy: 0.587444, val accuracy: 0.560000\n",
      "Epoch: 61.000000, Loss: 1.680571, Train accuracy: 0.594667, val accuracy: 0.567000\n",
      "Epoch: 62.000000, Loss: 1.282330, Train accuracy: 0.589333, val accuracy: 0.573000\n",
      "Epoch: 63.000000, Loss: 1.468876, Train accuracy: 0.592778, val accuracy: 0.568000\n",
      "Epoch: 64.000000, Loss: 1.449241, Train accuracy: 0.597667, val accuracy: 0.570000\n",
      "Epoch: 65.000000, Loss: 1.679536, Train accuracy: 0.599000, val accuracy: 0.567000\n",
      "Epoch: 66.000000, Loss: 1.179362, Train accuracy: 0.602333, val accuracy: 0.583000\n",
      "Epoch: 67.000000, Loss: 1.526690, Train accuracy: 0.599778, val accuracy: 0.576000\n",
      "Epoch: 68.000000, Loss: 1.455452, Train accuracy: 0.599889, val accuracy: 0.584000\n",
      "Epoch: 69.000000, Loss: 1.120906, Train accuracy: 0.604889, val accuracy: 0.579000\n",
      "Epoch: 70.000000, Loss: 1.377415, Train accuracy: 0.596667, val accuracy: 0.581000\n",
      "Epoch: 71.000000, Loss: 1.304334, Train accuracy: 0.605111, val accuracy: 0.577000\n",
      "Epoch: 72.000000, Loss: 1.368681, Train accuracy: 0.607444, val accuracy: 0.584000\n",
      "Epoch: 73.000000, Loss: 1.461526, Train accuracy: 0.605000, val accuracy: 0.579000\n",
      "Epoch: 74.000000, Loss: 1.528437, Train accuracy: 0.610444, val accuracy: 0.580000\n",
      "Epoch: 75.000000, Loss: 1.557555, Train accuracy: 0.606111, val accuracy: 0.578000\n",
      "Epoch: 76.000000, Loss: 1.459242, Train accuracy: 0.607444, val accuracy: 0.579000\n",
      "Epoch: 77.000000, Loss: 1.588894, Train accuracy: 0.604111, val accuracy: 0.582000\n",
      "Epoch: 78.000000, Loss: 1.487087, Train accuracy: 0.613000, val accuracy: 0.581000\n",
      "Epoch: 79.000000, Loss: 1.477731, Train accuracy: 0.613889, val accuracy: 0.583000\n",
      "Epoch: 80.000000, Loss: 1.262303, Train accuracy: 0.612000, val accuracy: 0.589000\n",
      "Epoch: 81.000000, Loss: 1.340186, Train accuracy: 0.603333, val accuracy: 0.573000\n",
      "Epoch: 82.000000, Loss: 1.409196, Train accuracy: 0.608222, val accuracy: 0.585000\n",
      "Epoch: 83.000000, Loss: 1.033743, Train accuracy: 0.617444, val accuracy: 0.589000\n",
      "Epoch: 84.000000, Loss: 1.511640, Train accuracy: 0.617444, val accuracy: 0.592000\n",
      "Epoch: 85.000000, Loss: 1.275686, Train accuracy: 0.614222, val accuracy: 0.587000\n",
      "Epoch: 86.000000, Loss: 1.341005, Train accuracy: 0.608889, val accuracy: 0.584000\n",
      "Epoch: 87.000000, Loss: 1.478969, Train accuracy: 0.620556, val accuracy: 0.596000\n",
      "Epoch: 88.000000, Loss: 1.320145, Train accuracy: 0.633333, val accuracy: 0.597000\n",
      "Epoch: 89.000000, Loss: 1.200962, Train accuracy: 0.633667, val accuracy: 0.586000\n",
      "Epoch: 90.000000, Loss: 1.407398, Train accuracy: 0.640111, val accuracy: 0.598000\n",
      "Epoch: 91.000000, Loss: 1.590185, Train accuracy: 0.637444, val accuracy: 0.606000\n",
      "Epoch: 92.000000, Loss: 1.373781, Train accuracy: 0.640778, val accuracy: 0.605000\n",
      "Epoch: 93.000000, Loss: 1.135611, Train accuracy: 0.644889, val accuracy: 0.602000\n",
      "Epoch: 94.000000, Loss: 1.328407, Train accuracy: 0.649111, val accuracy: 0.611000\n",
      "Epoch: 95.000000, Loss: 0.972117, Train accuracy: 0.643333, val accuracy: 0.606000\n",
      "Epoch: 96.000000, Loss: 1.514505, Train accuracy: 0.652333, val accuracy: 0.611000\n",
      "Epoch: 97.000000, Loss: 1.297560, Train accuracy: 0.647222, val accuracy: 0.612000\n",
      "Epoch: 98.000000, Loss: 1.113807, Train accuracy: 0.653111, val accuracy: 0.610000\n",
      "Epoch: 99.000000, Loss: 1.512432, Train accuracy: 0.653556, val accuracy: 0.604000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rate = 1e-2\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.995\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, \n",
    "                  dataset, MomentumSGD(), \n",
    "                  learning_rate=learning_rate,\n",
    "                  num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  learning_rate_decay=learning_rate_decay\n",
    "                 )\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = model\n",
    "best_loss_history = loss_history\n",
    "best_train_history = train_history\n",
    "best_val_history = val_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5386630710>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.549000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcourse_ai_venv",
   "language": "python",
   "name": "dlcourse_ai_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
